geom_point()+
xlab("Temperature")+
ylab("Dew_Point Temp")+
geom_smooth(method = "lm", se = FALSE)+
theme_pubclean()
t2 <- ggplot(train, aes(x = temperature, y = humidity))+
geom_point()+
xlab("Temperature")+
ylab("Humidity")+
geom_smooth(method = "lm", se = FALSE)+
theme_pubclean()
t3 <- ggplot(train, aes(x = temperature, y = wind_speed))+
geom_point()+
xlab("Temperature")+
ylab("Wind Speed")+
geom_smooth(method = "lm", se = FALSE)+
theme_pubclean()
t4 <- ggplot(train, aes(x = temperature, y = solar_radiation))+
geom_point()+
xlab("Temperature")+
ylab("Solar Radiation")+
geom_smooth(method = "lm", se = FALSE)+
theme_pubclean()
t5 <- ggplot(train, aes(x = temperature, y = rainfall))+
geom_point() +
xlab("Temperature")+
ylab("Rainfall")+
geom_smooth(method = "lm", se = FALSE)+
theme_pubclean()
t6 <- ggplot(train, aes(x = temperature, y = snowfall))+
geom_point()+
xlab("Temperature")+
ylab("Snowfall")+
geom_smooth(method = "lm", se = FALSE)+
theme_pubclean()
t7 <- ggplot(train, aes(y = temperature, x = factor(year), colour = factor(year)))+
geom_boxplot()+
theme_pubclean()+
theme(legend.position = "None")+
xlab("Year")+
ylab("Temperature")
t8 <- ggplot(train, aes(y = temperature, x = factor(month), color = factor(month)))+
geom_boxplot()+
theme_pubclean()+
theme(legend.position = "None")+
xlab("Month")+
ylab("Temperature")
train$hour <- as.factor(train$hour)
t9 <- train %>%
group_by(hour) %>%
summarise(temp_hour = mean(temperature)) %>%
ggplot(aes(y = temp_hour, x = hour))+
geom_point(colour = "dark green", size = 2) +
theme_pubclean()+
xlab("Hour")+
ylab("Mean Temperature")
ggarrange(t1,t2,t3,t4,t5,t6,t7,t8,t9, labels = c(1,2,3,4,5,6,7,8,9))
s1 <- ggplot(train, aes(x=seasons, y=temperature, fill = seasons)) +
geom_boxplot()+
theme_classic()+
xlab('Seasons')+
ylab('Temperature')+
scale_x_discrete(limits = c("Spring", "Summer", "Autumn", "Winter"))+
theme(legend.position = "None")+
scale_fill_brewer(palette="BuPu")
s2 <- ggplot(train, aes(x=seasons, y=humidity, fill = seasons)) +
geom_boxplot()+
theme_classic()+
xlab('Seasons')+
ylab('Humidity')+
scale_x_discrete(limits = c("Spring", "Summer", "Autumn", "Winter"))+
theme(legend.position = "None")+
scale_fill_brewer(palette="BuPu")
s3 <- ggplot(train, aes(x=seasons, y=wind_speed, fill = seasons)) +
geom_boxplot()+
theme_classic()+
xlab('Seasons')+
ylab('Wind Speed')+
scale_x_discrete(limits = c("Spring", "Summer", "Autumn", "Winter"))+
theme(legend.position = "None")+
scale_fill_brewer(palette="BuPu")
s4 <- ggplot(train, aes(x=seasons, y=dew_point_temperature, fill = seasons)) +
geom_boxplot()+
theme_classic()+
xlab('Seasons')+
ylab('Dew Point Temperature')+
scale_x_discrete(limits = c("Spring", "Summer", "Autumn", "Winter"))+
theme(legend.position = "None")+
scale_fill_brewer(palette="BuPu")
s5 <- ggplot(train, aes(x=seasons, y=solar_radiation, fill = seasons)) +
geom_boxplot()+
theme_classic()+
scale_y_log10()+
xlab('Seasons')+
ylab('Solar Radiation (Log)')+
scale_x_discrete(limits = c("Spring", "Summer", "Autumn", "Winter"))+
theme(legend.position = "None")+
scale_fill_brewer(palette="BuPu")
s6 <- ggplot(train, aes(x=seasons, y=snowfall, fill = seasons)) +
geom_boxplot()+
theme_classic()+
xlab('Seasons')+
ylab('Snowfall (Log)')+
scale_x_discrete(limits = c("Spring", "Summer", "Autumn", "Winter"))+
scale_y_log10()+
theme(legend.position = "None")+
scale_fill_brewer(palette="BuPu")
ggarrange(s1,s2,s3,s4,s5,s6)
### Poisson regression
train %>%
select(-c('date', 'season')) -> train
str(train)
train$hour <- factor(train$hour)
train$holiday <- factor(train$holiday)
train$functioning_day <- factor(train$functioning_day)
train$year <- factor(train$year)
train$month <- factor(train$month)
train$weekday <- factor(train$weekday)
mod.pois <- glm(count~ . , data=train, family=poisson)
summary(mod.pois)
test %>%
select(-c('date')) -> new
new$holiday <- as.factor(new$holiday)
new$holiday <- as.numeric(new$holiday)
new$holiday <- as.factor(new$holiday)
new$functioning_day <- as.factor(new$functioning_day)
new$functioning_day <- as.numeric(new$functioning_day)
new$functioning_day <- as.factor(new$functioning_day)
new$weekday <- as.numeric(new$weekday)
new$hour <- as.factor(new$hour)
new$seasons <- as.factor(new$seasons)
new$year <- as.factor(new$year)
new$month <- as.factor(new$month)
new$weekday <- as.factor(new$weekday)
poisson_bike <- predict(mod.pois, newdata = new, type="response")
poisson_bike %>%
round() -> poisson_predict
data.frame(actual=test$count, predicted=poisson_predict) %>%
ggplot(aes(x=predicted, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
sqrt(mean((test$count - poisson_predict)^2))
install.packages("Metrics")
library(Metrics)
rmse(test$count, poisson_predict)
## Lasso
library(glmnet)
y <- train$count
x <- data.matrix(train[,])
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#produce plot of test MSE by lambda value
plot(cv_model)
#find coefficients of best model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
# new1 <- data.matrix(test[, ])
#use lasso regression model to predict response value
predicted_lasso <- predict(best_model, s = best_lambda, newx = x)
rmse(test$count, predicted_lasso)
#use fitted best model to make predictions
y_predicted <- predict(best_model, s = best_lambda, newx = x)
#find SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# https://www.statology.org/lasso-regression-in-r/
new <- as.data.frame(x)
predicted_lasso %>%
round() -> predict_lasso_round
data.frame(actual=test$count, predicted=predict_lasso_round) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
# Best subset selection
library(boot)
library(tidyverse)
library(mosaic)
library(leaps)
rf <- regsubsets(count ~ ., train, nvmax = 40, method = "forward")
r_summary <- summary(rf)
r_summary
r_summary$adjr2
par(mfrow = c(1,3))
plot(r_summary$cp, xlab="Number of Variables", ylab="Cp", type = "l")
plot(r_summary$bic, xlab="Number of Variables", ylab="BIC", type ="l")
plot(r_summary$adjr2, xlab="Number of Variables", ylab="adjusted-R2", type = "l")
which.min(r_summary$cp) # lowest Cp value
which.min(r_summary$bic) # lowest bic value
which.max(r_summary$adjr2) # highest adjusted R^2 value
plot(rf, scale = "Cp")
plot(rf, scale = "bic")
plot(rf, scale = "adjr2")
coef(rf, 37) %>%
round()
fit <- glm(count ~ hour+temperature+humidity+rainfall+seasons+holiday+functioning_day+month+weekday, data = train)
summary(fit)
test_1 <- predict(fit, test)
# bike_share_count_predict = -718 -131*(hour2) -217*(hour3) -266*(hour4) -258*(hour5)
# -96(hour6) + 212*(hour7) +603*(hour8)+153*(hour9)+ 162*(hour16) + 410*(hour17) + 838*(hour18) + 564*(hour19)
# +478*(hour20)+497*(hour21)+394*(hour22)+172*(hour23)+30*(tempearture)-6*(humidity)+0*(visibility)-62(rainfall)
# -53(seasonsSummer)+141*(holiday2)+961*(functioning_day2)-79(month2)+89(month4)+382(month6)+150(month9)+312(month10)
# +0*(day) + 6*(weekday2)+28(weekday3)+61(weekday6)-19(weekday7)+231(month5)-176(month8)+245(month11)+33(month12)
data.frame(actual=test$count, predicted=test_1) %>%
ggplot(aes(x=predicted, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
rmse(test$count, test_1)
test_1 <- predict(fit, test)
# Best subset selection
library(boot)
library(tidyverse)
library(mosaic)
library(leaps)
rf <- regsubsets(count ~ ., train, nvmax = 40, method = "forward")
r_summary <- summary(rf)
r_summary
r_summary$adjr2
par(mfrow = c(1,3))
plot(r_summary$cp, xlab="Number of Variables", ylab="Cp", type = "l")
plot(r_summary$bic, xlab="Number of Variables", ylab="BIC", type ="l")
plot(r_summary$adjr2, xlab="Number of Variables", ylab="adjusted-R2", type = "l")
which.min(r_summary$cp) # lowest Cp value
which.min(r_summary$bic) # lowest bic value
which.max(r_summary$adjr2) # highest adjusted R^2 value
plot(rf, scale = "Cp")
plot(rf, scale = "bic")
plot(rf, scale = "adjr2")
coef(rf, 37) %>%
round()
fit <- glm(count ~ hour+temperature+humidity+rainfall+seasons+holiday+functioning_day+month+weekday, data = train)
summary(fit)
str(train)
test_1 <- predict(fit, test)
str(test)
test$hour <- as.factor(test$hour)
test_1 <- predict(fit, test)
summary(fit)
test
str(test)
test$holiday <- as.factor(test$holiday)
test$holiday <- as.numeric(test$holiday)
test$holiday <- as.factor(test$holiday)
test$functioning_day <- as.factor(test$functioning_day)
test$functioning_day <- as.numeric(test$functioning_day)
test$functioning_day <- as.factor(test$functioning_day)
test$weekday <- as.numeric(test$weekday)
test$hour <- as.factor(test$hour)
test$seasons <- as.factor(test$seasons)
test$year <- as.factor(test$year)
test$month <- as.factor(test$month)
test$weekday <- as.factor(test$weeday)
test$weekday <- as.factor(test$weekday)
test_1 <- predict(fit, test)
test_1 <- predict(fit, test)
str(test)
test_1 <- predict(fit, test)
fit <- lm(count ~ hour+temperature+humidity+rainfall+seasons+holiday+functioning_day+month+weekday, data = train)
summary(fit)
str(test)
test_1 <- predict(fit, test)
library(glmnet)
y <- train$count
x <- data.matrix(train[,])
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1, family = "poisson")
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#produce plot of test MSE by lambda value
plot(cv_model)
#find coefficients of best model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
# new1 <- data.matrix(test[, ])
#use lasso regression model to predict response value
predicted_lasso <- predict(best_model, s = best_lambda, newx = x)
rmse(test$count, predicted_lasso)
#use fitted best model to make predictions
y_predicted <- predict(best_model, s = best_lambda, newx = x)
#find SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# https://www.statology.org/lasso-regression-in-r/
new <- as.data.frame(x)
predicted_lasso %>%
round() -> predict_lasso_round
data.frame(actual=test$count, predicted=predict_lasso_round) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
best_lambda
rmse(test$count, poisson_predict)
rmse(train$count, predicted_lasso)
#use fitted best model to make predictions
y_predicted <- predict(best_model, s = best_lambda, newx = x)
predicted_lasso
names(predicted_lasso)
dim(predicted_lasso)
new <- as.data.frame(x)
predicted_lasso
predicted_lasso <- predict(best_model, s = best_lambda, newx = x, type = "response")
predicted_lasso %>%
round() -> predict_lasso_round
data.frame(actual=test$count, predicted=predict_lasso_round) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
data.frame(actual=test$count, predicted=predicted_lasso) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
data.frame(actual=train$count, predicted=predicted_lasso) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
predicted_lasso <- predict(best_model, s = best_lambda, newx = x, type = "response")
y_predicted <- predict(best_model, s = best_lambda, newx = x)
predicted_lasso <- predict(best_model, s = best_lambda, newx = x, type = "response")
data.frame(actual=train$count, predicted=predicted_lasso) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
head(cbind(train$count,predicted_lasso))
sqrt(mean((train$count - predicted_lasso)^2))
cv_model <- cv.glmnet(x, y, alpha = 1, family = "poisson")
best_lambda <- cv_model$lambda.min
best_lambda
sqrt(mean((train$count - predicted_lasso)^2))
sqrt(mean((train$count - predicted_lasso)^2)) - best_lambda
View(x)
seoulBike <- read_csv("SeoulBikeData_1.csv") # Import data
View(seoulBike)
str(x)
x$seasons
cv_model$cvm
train$seasons
train$holiday
cv_model <- cv.glmnet(x, y, alpha = 1, family = "poisson", nfolds = 5)
lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
cv_model <- cv.glmnet(x, y, alpha = 1, family = "poisson", nfolds = 5)
best_lambda <- cv_model$lambda.min
best_lambda
head(x)
## Lasso
library(glmnet)
y <- train$count
x <- data.matrix(train[,-1])
head(x)
set.seed(10)
cv_model <- cv.glmnet(x, y, alpha = 1, family = "poisson", nfolds = 5)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#produce plot of test MSE by lambda value
plot(cv_model)
#find coefficients of best model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
# new1 <- data.matrix(test[, ])
#use lasso regression model to predict response value
predicted_lasso <- predict(best_model, s = best_lambda, newx = x, type = "response")
dim(predicted_lasso)
# rmse(train$count, predicted_lasso)
#use fitted best model to make predictions
y_predicted <- predict(best_model, s = best_lambda, newx = x)
#find SST and SSE
# sst <- sum((y - mean(y))^2)
#sse <- sum((y_predicted - y)^2)
#find R-Squared
# rsq <- 1 - sse/sst
# rsq
# https://www.statology.org/lasso-regression-in-r/
new <- as.data.frame(x)
#predicted_lasso %>%
#  round() -> predict_lasso_round
data.frame(actual=train$count, predicted=predicted_lasso) %>%
ggplot(aes(x=s1, y=actual)) +
geom_point() +
geom_abline(intercept=0, slope=1, color = 'red')+
labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')
head(cbind(train$count,predicted_lasso))
sqrt(mean((train$count - predicted_lasso)^2)) - best_lambda
Spotify_Music
colnames(Spotify_Music)
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_popularity_genre = mean(popularity)) %>%
summarise(m_danceability_genre = mean(danceability)) %>%
summarise(m_energy_genre = mean(energy)) %>%
summarise(m_loudness_genre = mean(loudness)) %>%
summarise(m_acousticness_genre = mean(acousticness)) %>%
summarise(m_tempo_genre = mean(tempo)) %>%
summarise(m_duration_ms_genre = mean(duration_ms)) %>%
summarise(m_valence_genre = mean(valence)) %>%
summarise(m_liveness_genre = mean(liveness)) -> m_genre-music
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_popularity_genre = mean(popularity))
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_popularity_genre = mean(popularity)) %>%
summarise(m_danceability_genre = mean(danceability))
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_popularity_genre = mean(popularity)) -> a
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_danceability_genre = mean(danceability)) -> b
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_energy_genre = mean(energy)) -> c
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_loudness_genre = mean(loudness)) -> d
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_acousticness_genre = mean(acousticness)) -> e
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_tempo_genre = mean(tempo)) -> f
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_duration_ms_genre = mean(duration_ms)) -> g
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_valence_genre = mean(valence))-> h
Spotify_Music %>%
group_by(genre, subgenre) %>%
summarise(m_liveness_genre = mean(liveness)) -> i
View(i)
View(subgenre_music1)
View(subgenre_music)
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_popularity_genre = mean(popularity)) -> a
View(a)
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_popularity_genre = mean(popularity)) -> a
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_danceability_genre = mean(danceability)) -> b
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_energy_genre = mean(energy)) -> c
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_loudness_genre = mean(loudness)) -> d
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_acousticness_genre = mean(acousticness)) -> e
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_tempo_genre = mean(tempo)) -> f
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_duration_ms_genre = mean(duration_ms)) -> g
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_valence_genre = mean(valence))-> h
Spotify_Music %>%
group_by(genre, subgenre, year) %>%
summarise(m_liveness_genre = mean(liveness)) -> i
View(a)
library(dplyr)
inner_join(a,b,by=c("genre", "subgenre", "year"))  -> ab
View(ab)
inner_join(a,b,by=c("genre", "subgenre", "year"))  -> ab
inner_join(ab,c,by=c("genre", "subgenre", "year"))  -> abc
inner_join(abc,d,by=c("genre", "subgenre", "year"))  -> abcd
inner_join(abcd,e,by=c("genre", "subgenre", "year"))  -> abcde
inner_join(abcde,f,by=c("genre", "subgenre", "year"))  -> abcdef
inner_join(abcdef,g,by=c("genre", "subgenre", "year"))  -> abcdefg
inner_join(abcdefg,h,by=c("genre", "subgenre", "year"))  -> abcdefgh
inner_join(abcdefgh,i,by=c("genre", "subgenre", "year"))  -> subgenre_genre_year_mean
write.csv(subgenre_genre_year_mean, "subgenre_genre_year_mean.csv")
setwd("~/Desktop/SPRING2022/CSC-485/Final_Project/CSC_485_Group/data")
write.csv(subgenre_genre_year_mean, "subgenre_genre_year_mean.csv")
View(subgenre_genre_year_mean)
setwd("~/Desktop/SPRING2022/CSC-485/Final_Project/CSC_485_Group/data")
library(tidyverse)
Spotify_Music <- read_csv("Spotify_Music.csv")
View(Spotify_Music)
colnames(Spotify_Music)
library(tidyverse)
Spotify_Music <- read_csv("Spotify_Music.csv")
colnames(Spotify_Music)
Spotify_Music %>%
select(c( "genre", "popularity","danceability", "energy", "loudness",  "acousticness", "valence",
"liveness", "tempo", "duration_ms"
)) -> histogram_data
View(histogram_data)
write.csv(histogram_data, "histogram_data.csv")
